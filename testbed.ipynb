{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as NN\n",
    "import torch.nn.functional as F\n",
    "import models\n",
    "import losses\n",
    "from util import *\n",
    "import numpy.random as RNG\n",
    "from datasets import MNISTMulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mnist = MNISTMulti('.', n_digits=1, backrand=128, image_rows=70, image_cols=70)\n",
    "batch_size = 32\n",
    "mnist_dataloader = T.utils.data.DataLoader(mnist, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 70, 70])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 4])\n",
      "[3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB3IpptauPTHEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2bb63724e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as PL\n",
    "i = 2500\n",
    "PL.imshow(mnist.train_data[i].numpy(), cmap='gray')\n",
    "print(mnist.train_locs.size())\n",
    "addbox(PL.gca(), mnist.train_locs[i, 0].numpy(), 'red')\n",
    "#addbox(PL.gca(), mnist.train_locs[i, 1].numpy(), 'red')\n",
    "#addbox(PL.gca(), mnist.train_locs[i, 2].numpy(), 'red')\n",
    "print(mnist.train_labels[i].numpy())\n",
    "PL.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cnn.0.weight', 'cnn.0.bias', 'cnn.2.weight', 'cnn.2.bias', 'cnn.4.weight', 'cnn.4.bias', 'lstm.weight_ih', 'lstm.weight_hh', 'lstm.bias_ih', 'lstm.bias_hh', 'proj_y.0.weight', 'proj_y.0.bias', 'proj_y.2.weight', 'proj_y.2.bias', 'proj_p.0.weight', 'proj_p.0.bias', 'proj_p.2.weight', 'proj_p.2.bias', 'proj_B.0.weight', 'proj_B.0.bias', 'proj_B.2.weight', 'proj_B.2.bias', 'y_in.weight'])\n",
      "0 0 -3.6875 [-0.4380488]\n",
      "_y [6 3 6 3 3 0 6 2 8 7 4 4 3 9 4 1 2 3 4 0 6 0 5 2 2 7 0 4 3 1 6 1]\n",
      "y_hat [[3 3 6 6 0 3 4 7 8 4]\n",
      " [8 0 7 8 9 0 0 8 5 5]\n",
      " [2 4 9 3 8 9 6 4 7 9]\n",
      " [0 9 9 8 2 3 5 9 3 3]\n",
      " [1 5 6 9 0 2 3 6 9 8]\n",
      " [7 5 3 5 3 1 3 0 9 5]\n",
      " [1 7 5 8 4 3 2 0 5 2]\n",
      " [4 8 3 5 6 1 0 7 8 7]\n",
      " [6 1 9 7 1 4 4 8 9 0]\n",
      " [9 7 7 4 0 4 4 8 5 6]\n",
      " [2 2 1 0 8 2 3 5 4 0]\n",
      " [0 1 3 5 0 4 1 5 4 0]\n",
      " [6 5 0 5 0 2 6 3 8 0]\n",
      " [4 4 8 9 3 2 4 2 7 9]\n",
      " [2 9 3 6 5 3 0 9 1 6]\n",
      " [5 5 8 8 9 4 5 4 6 1]\n",
      " [2 4 8 7 5 1 6 1 0 8]\n",
      " [7 3 0 8 1 3 3 6 6 0]\n",
      " [8 1 2 4 5 9 5 4 0 1]\n",
      " [8 8 3 9 1 4 7 3 7 0]\n",
      " [4 4 0 6 8 4 0 7 2 9]\n",
      " [6 3 9 5 5 8 7 7 9 4]\n",
      " [0 7 5 4 4 8 1 0 9 8]\n",
      " [4 0 0 5 6 0 6 5 6 9]\n",
      " [8 8 4 5 3 2 3 0 3 1]\n",
      " [2 4 0 8 6 7 2 4 1 0]\n",
      " [2 9 2 6 8 4 5 8 3 1]\n",
      " [1 1 8 4 1 9 6 9 7 5]\n",
      " [0 6 5 5 3 4 2 0 2 8]\n",
      " [6 6 6 1 8 0 2 4 8 9]\n",
      " [9 2 9 9 4 0 0 5 0 5]\n",
      " [5 9 4 3 1 6 0 7 3 4]]\n",
      "p [[1. 1. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      " [0. 1. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      " [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [1. 1. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 0. 0. 0. 1. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 1. 1. 0.]]\n",
      "0 0 -0.875 [-0.02255536]\n",
      "0 0 -0.9375 [-0.04700924]\n",
      "0 0 -1.0 [-0.03987125]\n",
      "0 0 -0.875 [-0.0306696]\n",
      "0 0 -0.6875 [-0.0266767]\n",
      "0 0 -0.75 [-0.00892799]\n",
      "0 0 -0.5 [0.00950018]\n",
      "0 0 -0.625 [-0.02669515]\n",
      "0 0 -0.625 [-0.00581933]\n",
      "0 0 -0.625 [1.0427902e-08]\n",
      "_y [6 3 6 3 3 0 6 2 8 7 4 4 3 9 4 1 2 3 4 0 6 0 5 2 2 7 0 4 3 1 6 1]\n",
      "y_hat [[3 3 2 3 3 3 3 0 3 0]\n",
      " [3 3 0 0 3 2 3 0 3 3]\n",
      " [3 6 3 3 0 3 3 3 6 3]\n",
      " [3 3 3 3 3 3 3 4 7 3]\n",
      " [3 3 3 0 3 0 3 6 3 3]\n",
      " [3 3 7 6 3 3 0 6 3 3]\n",
      " [3 0 3 3 6 0 0 4 6 3]\n",
      " [3 3 3 6 3 8 3 3 3 0]\n",
      " [3 4 3 3 2 2 3 3 1 2]\n",
      " [3 3 7 7 6 3 3 8 7 0]\n",
      " [3 3 0 1 0 3 7 3 7 6]\n",
      " [3 8 3 3 3 3 3 7 3 6]\n",
      " [3 3 3 3 4 3 3 4 3 0]\n",
      " [3 3 6 2 3 3 3 3 9 9]\n",
      " [3 2 8 3 0 6 3 3 6 3]\n",
      " [3 6 3 3 0 3 3 0 3 3]\n",
      " [3 3 3 3 1 3 3 0 3 9]\n",
      " [3 3 3 8 1 6 0 3 3 3]\n",
      " [3 3 7 3 0 3 6 4 0 3]\n",
      " [3 3 3 3 6 2 3 6 3 3]\n",
      " [3 3 3 3 3 6 3 0 3 3]\n",
      " [3 3 3 3 3 3 4 4 4 0]\n",
      " [3 3 3 3 3 3 3 1 3 6]\n",
      " [3 7 3 0 3 6 9 3 3 3]\n",
      " [3 0 3 6 3 3 3 3 3 3]\n",
      " [3 3 3 0 2 5 3 3 1 7]\n",
      " [3 6 2 3 3 6 7 6 0 4]\n",
      " [3 3 3 3 3 3 3 0 2 3]\n",
      " [3 3 3 3 3 3 4 3 3 8]\n",
      " [3 3 0 3 3 3 0 3 3 3]\n",
      " [3 3 3 6 3 3 0 0 3 6]\n",
      " [3 1 3 3 3 1 3 3 9 0]]\n",
      "p [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "0 0 -0.625 [9.295763e-09]\n",
      "0 0 -0.625 [5.903712e-09]\n",
      "0 0 -0.625 [8.435745e-09]\n",
      "0 0 -0.625 [7.0300303e-09]\n",
      "0 0 -0.625 [-0.00709795]\n",
      "0 0 -0.625 [5.7589205e-09]\n",
      "0 0 -0.625 [4.0781742e-09]\n",
      "0 0 -0.625 [4.0865418e-09]\n",
      "0 0 -0.625 [5.125912e-09]\n",
      "0 0 -0.625 [5.6672436e-09]\n",
      "_y [6 3 6 3 3 0 6 2 8 7 4 4 3 9 4 1 2 3 4 0 6 0 5 2 2 7 0 4 3 1 6 1]\n",
      "y_hat [[3 3 3 6 3 3 5 6 4 0]\n",
      " [3 3 6 3 3 2 0 3 3 6]\n",
      " [3 4 3 6 3 0 2 6 3 3]\n",
      " [3 3 3 3 3 3 6 3 0 3]\n",
      " [3 3 0 0 0 0 3 9 3 3]\n",
      " [3 3 3 0 3 3 9 3 3 0]\n",
      " [3 3 3 7 8 7 3 3 2 3]\n",
      " [3 0 3 3 1 7 3 8 3 3]\n",
      " [3 3 3 3 6 3 7 0 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 6 6 0 3 8 0 6 0 0]\n",
      " [3 3 7 3 3 6 8 3 3 3]\n",
      " [3 3 0 3 3 7 2 9 4 3]\n",
      " [3 3 6 3 3 3 3 3 2 6]\n",
      " [3 3 0 3 0 1 4 1 1 3]\n",
      " [3 3 7 3 3 9 3 6 3 3]\n",
      " [3 3 0 3 3 3 7 1 0 0]\n",
      " [3 6 6 3 3 3 7 3 3 3]\n",
      " [3 3 6 2 3 7 6 3 1 3]\n",
      " [3 3 3 9 3 0 1 0 2 3]\n",
      " [3 3 6 6 3 3 0 0 4 0]\n",
      " [3 3 3 0 3 3 7 3 0 0]\n",
      " [3 3 3 9 3 6 3 2 0 3]\n",
      " [3 6 6 5 0 4 6 1 6 4]\n",
      " [3 3 4 0 3 3 0 0 0 0]\n",
      " [3 3 3 0 3 6 0 0 4 0]\n",
      " [3 3 4 6 0 3 3 1 3 4]\n",
      " [3 2 0 3 3 2 3 2 0 3]\n",
      " [3 0 3 6 2 6 7 0 6 3]\n",
      " [3 0 2 6 3 6 2 7 0 3]\n",
      " [3 0 3 4 0 2 2 3 3 0]\n",
      " [3 3 1 6 1 3 0 3 3 6]]\n",
      "p [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "0 0 -0.625 [1.9518485e-08]\n",
      "0 0 -0.625 [2.8547948e-08]\n",
      "0 0 -0.625 [8.596544e-09]\n",
      "0 0 -0.625 [3.6081473e-09]\n",
      "0 0 -0.625 [1.7163984e-09]\n",
      "0 0 -0.625 [2.0190782e-09]\n",
      "0 0 -0.625 [2.0831066e-09]\n",
      "0 0 -0.625 [1.1513294e-09]\n",
      "0 0 -0.625 [6.577466e-10]\n",
      "0 0 -0.625 [1.2787496e-10]\n",
      "_y [6 3 6 3 3 0 6 2 8 7 4 4 3 9 4 1 2 3 4 0 6 0 5 2 2 7 0 4 3 1 6 1]\n",
      "y_hat [[3 3 6 2 6 3 8 2 3 3]\n",
      " [3 3 0 3 9 3 3 6 2 9]\n",
      " [3 0 0 0 3 3 3 2 1 0]\n",
      " [3 0 3 3 0 3 3 3 3 7]\n",
      " [3 3 8 3 3 1 3 3 3 8]\n",
      " [3 3 3 3 0 0 7 3 0 3]\n",
      " [3 3 9 6 6 3 6 6 3 3]\n",
      " [3 3 3 0 3 0 0 6 7 1]\n",
      " [3 3 9 4 3 3 3 9 0 3]\n",
      " [3 0 2 7 7 3 3 3 9 3]\n",
      " [3 4 3 3 3 0 0 3 0 0]\n",
      " [3 9 3 3 5 7 9 3 1 3]\n",
      " [3 3 0 3 9 2 2 4 0 4]\n",
      " [3 7 0 0 3 2 7 3 0 7]\n",
      " [3 6 7 6 0 7 3 6 2 6]\n",
      " [3 3 0 3 2 6 0 0 3 3]\n",
      " [3 3 3 3 3 0 0 0 0 0]\n",
      " [3 3 6 3 0 3 7 9 7 6]\n",
      " [3 1 4 3 0 0 1 8 3 3]\n",
      " [3 7 3 3 3 3 3 7 6 3]\n",
      " [3 3 7 7 3 1 0 3 6 6]\n",
      " [3 6 3 3 3 3 3 3 3 8]\n",
      " [3 0 3 0 8 4 1 3 3 3]\n",
      " [3 4 2 0 6 3 3 0 0 0]\n",
      " [3 4 3 9 3 3 0 0 2 6]\n",
      " [3 3 5 8 6 0 8 6 3 3]\n",
      " [3 2 3 0 6 0 3 0 6 1]\n",
      " [3 3 3 3 3 3 3 3 0 5]\n",
      " [3 3 0 1 0 0 6 7 3 0]\n",
      " [3 9 6 6 1 0 0 3 0 3]\n",
      " [3 3 3 6 3 3 6 3 5 3]\n",
      " [3 3 8 7 0 3 3 3 3 7]]\n",
      "p [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -0.625 [8.530151e-10]\n",
      "0 0 -0.625 [8.6365615e-10]\n",
      "0 0 -0.625 [5.857146e-10]\n",
      "0 0 -0.625 [7.258677e-10]\n",
      "0 0 -0.625 [7.1677275e-10]\n",
      "0 0 -0.625 [9.641553e-10]\n",
      "0 0 -0.625 [1.0802979e-09]\n",
      "0 0 -0.625 [1.0875738e-09]\n",
      "0 0 -0.625 [1.2323653e-09]\n",
      "0 0 -0.625 [1.1143129e-09]\n",
      "_y [6 3 6 3 3 0 6 2 8 7 4 4 3 9 4 1 2 3 4 0 6 0 5 2 2 7 0 4 3 1 6 1]\n",
      "y_hat [[3 3 3 3 2 3 0 0 6 7]\n",
      " [3 3 3 0 0 4 2 3 3 3]\n",
      " [3 3 3 3 6 0 3 6 1 0]\n",
      " [3 3 6 6 5 2 0 7 0 4]\n",
      " [3 3 4 3 3 2 3 2 6 3]\n",
      " [3 3 3 3 3 3 3 3 3 8]\n",
      " [3 0 3 3 3 0 8 3 3 3]\n",
      " [3 3 3 7 6 3 6 2 2 0]\n",
      " [3 3 7 2 4 0 3 3 3 3]\n",
      " [3 6 6 0 3 3 0 3 3 3]\n",
      " [3 3 3 6 0 3 3 6 5 9]\n",
      " [3 1 7 6 3 0 0 3 9 6]\n",
      " [3 3 3 1 9 4 3 3 3 3]\n",
      " [3 3 3 3 3 7 3 3 6 3]\n",
      " [3 3 7 3 0 3 3 6 6 3]\n",
      " [3 3 3 3 3 2 2 9 1 6]\n",
      " [3 3 6 3 6 0 7 3 9 2]\n",
      " [3 6 9 0 3 2 6 0 0 6]\n",
      " [3 3 3 3 0 6 3 4 3 3]\n",
      " [3 3 3 0 3 3 0 1 3 3]\n",
      " [3 0 3 2 1 6 3 4 1 7]\n",
      " [3 0 7 7 0 3 0 6 3 3]\n",
      " [3 3 0 0 0 0 3 3 3 0]\n",
      " [3 3 3 3 3 4 4 0 3 2]\n",
      " [3 3 3 3 8 3 0 3 3 3]\n",
      " [3 3 0 3 3 9 6 0 0 3]\n",
      " [3 3 3 3 0 3 3 3 6 3]\n",
      " [3 3 2 6 3 3 9 3 3 3]\n",
      " [3 0 3 3 3 3 6 9 3 8]\n",
      " [3 3 3 0 6 2 6 0 0 3]\n",
      " [3 3 3 3 0 3 0 9 3 3]\n",
      " [3 6 3 6 6 3 2 6 3 3]]\n",
      "p [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "0 0 -0.625 [9.267751e-10]\n",
      "0 0 -0.625 [1.22036e-09]\n",
      "0 0 -0.625 [9.591531e-10]\n",
      "0 0 -0.625 [7.010385e-10]\n",
      "0 0 -0.625 [6.2091204e-10]\n",
      "0 0 -0.625 [9.278665e-10]\n",
      "0 0 -0.625 [1.4142643e-09]\n",
      "0 0 -0.625 [6.2755135e-12]\n",
      "0 0 -0.625 [1.0049917e-11]\n",
      "0 0 -0.625 [-2.0695552e-10]\n",
      "_y [6 3 6 3 3 0 6 2 8 7 4 4 3 9 4 1 2 3 4 0 6 0 5 2 2 7 0 4 3 1 6 1]\n",
      "y_hat [[3 3 3 3 6 0 7 3 3 3]\n",
      " [3 3 3 3 1 0 3 6 3 3]\n",
      " [3 3 3 4 3 3 3 3 4 3]\n",
      " [3 3 3 0 3 0 6 3 3 3]\n",
      " [3 3 1 3 1 0 3 3 3 3]\n",
      " [3 3 3 1 3 3 0 3 0 3]\n",
      " [3 0 2 0 3 3 3 3 0 3]\n",
      " [3 3 0 0 3 2 6 4 3 3]\n",
      " [3 3 3 3 3 3 6 3 3 3]\n",
      " [3 3 3 3 0 6 3 3 3 3]\n",
      " [3 3 3 6 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 0 3]\n",
      " [3 3 3 3 3 0 3 3 3 3]\n",
      " [3 3 3 5 3 3 3 0 3 1]\n",
      " [3 3 1 3 0 3 3 0 3 3]\n",
      " [3 3 3 3 3 3 2 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 6]\n",
      " [3 3 3 3 3 3 3 6 1 2]\n",
      " [3 8 3 3 6 3 3 3 3 3]\n",
      " [3 3 3 6 3 3 3 3 6 3]\n",
      " [3 3 0 4 3 3 0 3 0 6]\n",
      " [3 3 3 3 0 6 3 3 3 0]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 7 3 3 3 7 3 3 3]\n",
      " [3 3 0 3 3 3 3 3 8 3]\n",
      " [3 3 3 3 3 3 3 3 4 0]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 6 9 3 3 0 3 0 6 3]\n",
      " [3 1 3 3 6 7 3 0 3 3]\n",
      " [3 3 3 3 3 3 3 0 3 3]\n",
      " [3 3 3 3 3 3 6 3 3 3]\n",
      " [3 3 3 3 3 3 3 7 3 3]]\n",
      "p [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "0 0 -0.625 [-6.398295e-11]\n",
      "0 0 -0.625 [2.9003785e-10]\n",
      "0 0 -0.625 [-2.211209e-10]\n",
      "0 0 -0.625 [-4.3442014e-10]\n",
      "0 0 -0.625 [4.1363818e-10]\n",
      "0 0 -0.625 [4.777121e-10]\n",
      "0 0 -0.625 [9.347787e-10]\n",
      "0 0 -0.625 [7.86531e-10]\n",
      "0 0 -0.625 [2.1782398e-10]\n",
      "0 0 -0.625 [5.961738e-11]\n",
      "_y [6 3 6 3 3 0 6 2 8 7 4 4 3 9 4 1 2 3 4 0 6 0 5 2 2 7 0 4 3 1 6 1]\n",
      "y_hat [[3 3 3 3 3 6 3 3 8 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 0]\n",
      " [3 3 3 3 3 3 4 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 0 3 3 3 3]\n",
      " [3 3 3 3 6 0 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 4 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 6 3 3 3 3 8 3 3]\n",
      " [3 3 3 3 3 3 3 3 4 3]\n",
      " [3 6 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 2 3 3 3 3 3 3]\n",
      " [3 6 3 6 6 3 3 3 6 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 4 3 6 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3]]\n",
      "p [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "0 0 -0.625 [5.97538e-11]\n",
      "0 0 -0.625 [6.089067e-11]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-965d5d13b9c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtovar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat_logprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_logprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat_logprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_logprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML/hierarchical-object-detection/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, feedback)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mv_B_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglimpse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_B\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mv_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0min_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_B\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML/hierarchical-object-detection/glimpse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, spatial_att)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# (batch_size, n_glims, att_params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mabsolute_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_absolute_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_att\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mglims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_gaussian_glims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_att\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mglims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML/hierarchical-object-detection/glimpse.py\u001b[0m in \u001b[0;36mextract_gaussian_glims\u001b[0;34m(x, a, glim_size)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# (batch_size, n_glims, nchannels, n_glim_rows, n_glim_cols)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mFx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rdiv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mtensor1_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_batch_portion\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtensor1_exp_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_batch_portion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensor1_exp_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mtensor2_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_batch_portion\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtensor2_exp_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_batch_portion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensor2_exp_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcontiguous\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.SequentialGlimpsedClassifier()\n",
    "opt = T.optim.Adam(model.parameters())\n",
    "loss_fn = losses.RLClassifierLoss()\n",
    "ones = T.ones(batch_size, 10).long()\n",
    "\n",
    "print(dict(model.named_parameters()).keys())\n",
    "\n",
    "for epoch in range(1):\n",
    "    for i, (x, _y, B) in enumerate(mnist_dataloader):\n",
    "        batch_size, n_rows, n_cols = x.size()\n",
    "        y = T.LongTensor(batch_size, 10).zero_().scatter_add_(1, _y, ones)\n",
    "        x = tovar(x.float() / 255)\n",
    "        y = tovar(y)\n",
    "        B = tovar(B)\n",
    "        for j in range(1000000):\n",
    "            y_hat, y_hat_logprob, p, p_logprob = model(x.unsqueeze(1).expand(batch_size, 3, n_rows, n_cols))\n",
    "            loss = loss_fn(y, y_hat, y_hat_logprob, p, p_logprob)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            grad_clip(model.parameters(), 1)\n",
    "            opt.step()\n",
    "            if j % 100 == 0:\n",
    "                print(epoch, i, tonumpy(loss_fn.r).sum(1).mean(), tonumpy(loss))\n",
    "                if j % 1000 == 0:\n",
    "                    print('_y', tonumpy(_y).squeeze())\n",
    "                    print('y_hat', tonumpy(y_hat)[:, :, 0].squeeze())\n",
    "                    print('p', tonumpy(p)[:, :, 0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
